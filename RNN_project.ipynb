{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Recurrent Neural Network Projects\n",
    "\n",
    "Welcome to the Recurrent Neural Network Project in the Artificial Intelligence Nanodegree! In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully!\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation TODOs in this notebook\n",
    "\n",
    "This notebook contains two problems, cut into a variety of TODOs.  Make sure to complete each section containing a TODO marker throughout the notebook.  For convenience we provide links to each of these sections below.\n",
    "\n",
    "[TODO #1: Implement a function to window time series](#TODO_1)\n",
    "\n",
    "[TODO #2: Create a simple RNN model using keras to perform regression](#TODO_2)\n",
    "\n",
    "[TODO #3: Finish cleaning a large text corpus](#TODO_3)\n",
    "\n",
    "[TODO #4: Implement a function to window a large text corpus](#TODO_4)\n",
    "\n",
    "[TODO #5: Create a simple RNN model using keras to perform multiclass classification](#TODO_5)\n",
    "\n",
    "[TODO #6: Generate text using a fully trained RNN model and a variety of input sequences](#TODO_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Perform time series prediction \n",
    "\n",
    "In this project you will perform time series prediction using a Recurrent Neural Network regressor.  In particular you will re-create the figure shown in the notes - where the stock price of Apple was forecasted (or predicted) 7 days in advance.  In completing this exercise you will learn how to construct RNNs using Keras, which will also aid in completing the second project in this notebook.\n",
    "\n",
    "The particular network architecture we will employ for our RNN is known as  [Long Term Short Memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory), which helps significantly avoid technical problems with optimization of RNNs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting started\n",
    "\n",
    "First we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.\n",
    "\n",
    "Here we normalize the series to lie in the range [0,1] [using this scikit function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), but it is also commonplace to normalize by a series standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### Load in necessary libraries for data input and normalization\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_answers import *\n",
    "\n",
    "### load in and normalize the dataset\n",
    "dataset = np.loadtxt('datasets/normalized_apple_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a quick look at the (normalized) time series we'll be performing predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7face6749b00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUrigmJlZKVxQzMysFC4oZmZWiv8D0ajmVqfhrowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad34299a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets take a look at our time series\n",
    "plt.plot(dataset)\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('normalized series value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Cutting our time series into sequences\n",
    "\n",
    "Remember, our time series is a sequence of numbers that we can represent in general mathematically as \n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below.\n",
    "\n",
    "<img src=\"images/timeseries_windowing_training.gif\" width=600 height=600/>\n",
    "\n",
    "For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of length 5 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time for you to window the input time series as described above!  \n",
    "\n",
    "<a id='TODO_1'></a>\n",
    "\n",
    "**TODO:** Implement the function called **window_transform_series** in my_answers.py so that it runs a sliding window along the input series and creates associated input/output pairs.    Note that this function should input a) the series and b) the window length, and return the input/output subsequences.  Make sure to format returned input/output as generally shown in table above (where window_size = 5), and make sure your returned input is a numpy array.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your function on the list of odd numbers given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_nums = np.array([1,3,5,7,9,11,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a hard-coded solution for odd_nums.  You can compare its results with what you get from your **window_transform_series** implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the input X will look like ----\n",
      "[[ 1  3]\n",
      " [ 3  5]\n",
      " [ 5  7]\n",
      " [ 7  9]\n",
      " [ 9 11]]\n",
      "--- the associated output y will look like ----\n",
      "[[ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]]\n"
     ]
    }
   ],
   "source": [
    "# run a window of size 2 over the odd number sequence and display the results\n",
    "window_size = 2\n",
    "\n",
    "X = []\n",
    "X.append(odd_nums[0:2])\n",
    "X.append(odd_nums[1:3])\n",
    "X.append(odd_nums[2:4])\n",
    "X.append(odd_nums[3:5])\n",
    "X.append(odd_nums[4:6])\n",
    "\n",
    "y = odd_nums[2:]\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "y = np.reshape(y, (len(y),1)) #optional\n",
    "\n",
    "assert(type(X).__name__ == 'ndarray')\n",
    "assert(type(y).__name__ == 'ndarray')\n",
    "assert(X.shape == (5,2))\n",
    "assert(y.shape in [(5,1), (5,)])\n",
    "\n",
    "# print out input/output pairs --> here input = X, corresponding output = y\n",
    "print ('--- the input X will look like ----')\n",
    "print (X)\n",
    "\n",
    "print ('--- the associated output y will look like ----')\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again - you can check that your completed **window_transform_series** function works correctly by trying it on the odd_nums sequence - you should get the above output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement the function window_transform_series in the file my_answers.py\n",
    "from my_answers import window_transform_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  5]\n",
      " [ 3  5  7]\n",
      " [ 5  7  9]\n",
      " [ 7  9 11]]\n",
      "[[ 7]\n",
      " [ 9]\n",
      " [11]\n",
      " [13]]\n"
     ]
    }
   ],
   "source": [
    "X, y = window_transform_series(odd_nums, 3)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function in place apply it to the series in the Python cell below.  We use a window_size = 7 for these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window the data using your windowing function\n",
    "window_size = 7\n",
    "X,y = window_transform_series(series = dataset,window_size = window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Splitting into training and testing sets\n",
    "\n",
    "In order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.\n",
    "\n",
    "Note how here we are **not** splitting the dataset *randomly* as one typically would do when validating a regression model.  This is because our input/output pairs *are related temporally*.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points *within the timeframe of our training set*.  \n",
    "\n",
    "We want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict *future* values of a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset into training / testing sets\n",
    "train_test_split = int(np.ceil(2*len(y)/float(3)))   # set the split point\n",
    "\n",
    "# partition the training set\n",
    "X_train = X[:train_test_split,:]\n",
    "y_train = y[:train_test_split]\n",
    "\n",
    "# keep the last chunk for testing\n",
    "X_test = X[train_test_split:,:]\n",
    "y_test = y[train_test_split:]\n",
    "\n",
    "# NOTE: to use keras's RNN LSTM module our input must be reshaped to [samples, window size, stepsize] \n",
    "X_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\n",
    "X_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_2'></a>\n",
    "\n",
    "## 1.4  Build and run an RNN regression model\n",
    "\n",
    "Having created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications\n",
    "\n",
    "- layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))\n",
    "- layer 2 uses a fully connected module with one unit\n",
    "- the 'mean_squared_error' loss should be used (remember: we are performing regression here)\n",
    "\n",
    "This can be constructed using just a few lines - see e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LSTM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) \n",
    "\n",
    "(given in the cell below).  (remember to copy your completed function into the script *my_answers.py* function titled *build_part1_RNN* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: create required RNN model\n",
    "# import keras network libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "\n",
    "# given - fix random seed - so we can all reproduce the same results on our default time series\n",
    "np.random.seed(0)\n",
    "\n",
    "# TODO: implement build_part1_RNN in my_answers.py\n",
    "from my_answers import build_part1_RNN\n",
    "model = build_part1_RNN(window_size)\n",
    "\n",
    "# build model using keras documentation recommended optimizer initialization\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your model built you can now fit the model by activating the cell below!  Note: the number of epochs (np_epochs) and batch_size are preset (so we can all produce the same results).  You can choose to toggle the verbose parameter - which gives you regular updates on the progress of the algorithm - on and off by setting it to 1 or 0 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 2.15 s, total: 44.9 s\n",
      "Wall time: 28.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7facaf4326d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# run your model!\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=50, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Checking model performance\n",
    "\n",
    "With your model fit we can now make predictions on both our training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for training\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we compute training and testing errors using our trained model - you should be able to achieve at least\n",
    "\n",
    "*training_error* < 0.02\n",
    "\n",
    "and \n",
    "\n",
    "*testing_error* < 0.02\n",
    "\n",
    "with your fully trained model.  \n",
    "\n",
    "If either or both of your accuracies are larger than 0.02 re-train your model - increasing the number of epochs you take (a maximum of around 1,000 should do the job) and/or adjusting your batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.0160044318234\n",
      "testing error = 0.0139837342119\n"
     ]
    }
   ],
   "source": [
    "# print out training and testing errors\n",
    "training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('training error = ' + str(training_error))\n",
    "\n",
    "testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('testing error = ' + str(testing_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activating the next cell plots the original data, as well as both predictions on the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAEKCAYAAABkC+0BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facaf360908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot everything - the original series as well as predictions on training and testing sets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot original series\n",
    "plt.plot(dataset,color = 'k')\n",
    "\n",
    "# plot training set prediction\n",
    "split_pt = train_test_split + window_size \n",
    "plt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n",
    "\n",
    "# plot testing set prediction\n",
    "plt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n",
    "\n",
    "# pretty up graph\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('(normalized) price of Apple stock')\n",
    "plt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you can try out any time series for this exercise!  If you would like to try another see e.g., [this site containing thousands of time series](https://datamarket.com/data/list/?q=provider%3Atsdl) and pick another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Create a sequence generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Getting started\n",
    "\n",
    "In this project you will implement a popular Recurrent Neural Network (RNN) architecture to create an English language sequence generator capable of building semi-coherent English sentences from scratch by building them up character-by-character.  This will require a substantial amount amount of parameter tuning on a large training corpus (at least 100,000 characters long).  In particular for this project we will be using a complete version of Sir Arthur Conan Doyle's classic book The Adventures of Sherlock Holmes.\n",
    "\n",
    "How can we train a machine learning model to generate text automatically, character-by-character?  *By showing the model many training examples so it can learn a pattern between input and output.*  With this type of text generation each input is a string of valid characters like this one\n",
    "\n",
    "*dogs are grea*\n",
    "\n",
    "while the corresponding output is the next character in the sentence - which here is 't' (since the complete sentence is 'dogs are great').  We need to show a model many such examples in order for it to make reasonable predictions.\n",
    "\n",
    "**Fun note:** For those interested in how text generation is being used check out some of the following fun resources:\n",
    "\n",
    "- [Generate wacky sentences](http://www.cs.toronto.edu/~ilya/rnn.html) with this academic RNN text generator\n",
    "\n",
    "- Various twitter bots that tweet automatically generated text like[this one](http://tweet-generator-alex.herokuapp.com/).\n",
    "\n",
    "- the [NanoGenMo](https://github.com/NaNoGenMo/2016) annual contest to automatically produce a 50,000+ novel automatically\n",
    "\n",
    "- [Robot Shakespeare](https://github.com/genekogan/RobotShakespeare) a text generator that automatically produces Shakespear-esk sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Preprocessing a text dataset\n",
    "\n",
    "Our first task is to get a large text corpus for use in training, and on it we perform a several light pre-processing tasks.  The default corpus we will use is the classic book Sherlock Holmes, but you can use a variety of others as well - so long as they are fairly large (around 100,000 characters or more).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 581864 characters\n"
     ]
    }
   ],
   "source": [
    "# read in the text, transforming everything to lower case\n",
    "text = open('datasets/holmes.txt').read().lower()\n",
    "print('our original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets examine a bit of the raw text.  Because we are interested in creating sentences of English words automatically by building up each word character-by-character, we only want to train on valid English words.  In other words - we need to remove all of the other characters that are not part of English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ufeffproject gutenberg's the adventures of sherlock holmes, by arthur conan doyle\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n\\ntitle: the adventures of sherlock holmes\\n\\nauthor: arthur conan doyle\\n\\nposting date: april 18, 2011 [ebook #1661]\\nfirst posted: november 29, 2002\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook the adventures of sherlock holmes ***\\n\\n\\n\\n\\nproduced by an anonymous project gutenberg volunteer and jose menendez\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nthe adventures of sherlock holmes\\n\\nby\\n\\nsir arthur conan doyle\\n\\n\\n\\n   i. a scandal in bohemia\\n  ii. the red-headed league\\n iii. a case of identity\\n  iv. the boscombe valley mystery\\n   v. the five orange pips\\n  vi. the man with the twisted lip\\n vii. the adventure of the blue carbuncle\\nviii. the adventure of the speckled band\\n  ix. the adventure of the engineer's thumb\\n   x. the adventure of the noble bachelor\\n  xi. the adventure of the beryl coronet\\n xii. the adventure of the copper beeches\\n\\n\\n\\n\\nadventure i. a scandal in bohemia\\n\\ni.\\n\\nto sherlock holmes she is always the woman. i have seldom heard\\nhim mention her under any other name. in his eyes she eclipses\\nand predominates the whole of her sex. it was not that he felt\\nany emotion akin to love for irene adler. all emotions, and that\\none particularly, were abhorrent to his cold, precise but\\nadmirably balanced mind. he was, i take it, the most perfect\\nreasoning and observing machine that the world has seen, but as a\\nlover he would have placed himself in a false position. he never\\nspoke of the softer passions, save with a gibe and a sneer. they\\nwere admirable things for the observer--excellent for drawing the\\nveil from men's motives and actions. but for the trained reasoner\\nto admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a dist\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow - there's a lot of junk here (i.e., weird uncommon character combinations - as this first character chunk contains the title and author page, as well as table of contents)!  To keep things simple, we want to train our RNN on a large chunk of more typical English sentences - we don't want it to start thinking non-english words or strange characters are valid! - so lets clean up the data a bit.\n",
    "\n",
    "First, since the dataset is so large and the first few hundred characters contain a lot of junk, lets cut it out.  Lets also find-and-replace those newline tags with empty spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find and replace '\\n' and '\\r' symbols - replacing them \n",
    "text = text[1302:]\n",
    "text = text.replace('\\n',' ')    # replacing '\\n' with '' simply removes the sequence\n",
    "text = text.replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the first 1000 characters of our text looks now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer--excellent for drawing the veil from men's motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene ad\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 1000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_3'></a>\n",
    "\n",
    "#### TODO: finish cleaning the text\n",
    "\n",
    "Lets make sure we haven't left any other atypical characters (commas, periods, etc., are ok) lurking around in the depths of the text.  You can do this by enumerating all the text's unique characters, examining them, and then replacing any unwanted characters with empty spaces!  Once we find all of the text's unique characters, we can remove all of the atypical ones in the next cell.  Note: don't remove the punctuation marks given in my_answers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'è', 'é']\n"
     ]
    }
   ],
   "source": [
    "unique = sorted(list(set(text)))\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement cleaned_text in my_answers.py\n",
    "from my_answers import cleaned_text\n",
    "\n",
    "text = cleaned_text(text)\n",
    "\n",
    "# shorten any extra dead space created above\n",
    "text = text.replace('  ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', ',', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "unique = sorted(list(set(text)))\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your chosen characters removed print out the first few hundred lines again just to double check that everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is eyes she eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love for irene adler. all emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. he was, i take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. he never spoke of the softer passions, save with a gibe and a sneer. they were admirable things for the observer excellent for drawing the veil from men s motives and actions. but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more disturbing than a strong emotion in a nature such as his. and yet there was but one woman to him, and that woman was the late irene adler, of dubious and questionable memory. i had seen little of holmes lately. my marriage had drifted us away from each other. my own complete happiness, and the home centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while holmes, who loathed every form of society with his whole bohemian soul, remained in our lodgings in baker street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. he was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. from time to time i heard some vague account of his doings: of his summons to odessa in the case of the trepoff murder, of his clearing up o'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### print out the first 2000 characters of the raw text to get a sense of what we need to throw out\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have thrown out a good number of non-English characters/character sequences lets print out some statistics about the dataset - including number of total characters and number of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 570571 total number of characters\n",
      "this corpus has 33 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3  Cutting data into input/output pairs\n",
    "\n",
    "Now that we have our text all cleaned up, how can we use it to train a model to generate sentences automatically?  First we need to train a machine learning model - and in order to do that we need a set of input/output pairs for a model to train on.  How can we create a set of input/output pairs from our text to train on?\n",
    "\n",
    "Remember in part 1 of this notebook how we used a sliding window to extract input/output pairs from a time series?  We do the same thing here!  We slide a window of length $T$ along our giant text corpus - everything in the window becomes one input while the character following becomes its corresponding output.  This process of extracting input/output pairs is illustrated in the gif below on a small example text using a window size of T = 5.\n",
    "\n",
    "<img src=\"images/text_windowing_training.gif\" width=400 height=400/>\n",
    "\n",
    "Notice one aspect of the sliding window in this gif that does not mirror the analogous gif for time series shown in part 1 of the notebook - we do not need to slide the window along one character at a time but can move by a fixed step size $M$ greater than 1 (in the gif indeed $M = 1$).  This is done with large input texts (like ours which has over 500,000 characters!) when sliding the window along one character at a time we would create far too many input/output pairs to be able to reasonably compute with.\n",
    "\n",
    "More formally lets denote our text corpus - which is one long string of characters - as follows\n",
    "\n",
    "$$s_{0},s_{1},s_{2},...,s_{P}$$\n",
    "\n",
    "where $P$ is the length of the text (again for our text $P \\approx 500,000!$).  Sliding a window of size T = 5 with a step length of M = 1 (these are the parameters shown in the gif above) over this sequence produces the following list of input/output pairs\n",
    "\n",
    "\n",
    "$$\\begin{array}{c|c}\n",
    "\\text{Input} & \\text{Output}\\\\\n",
    "\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n",
    "\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n",
    "\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n",
    "\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n",
    "\\end{array}$$\n",
    "\n",
    "Notice here that each input is a sequence (or vector) of 5 characters (and in general has length equal to the window size T) while each corresponding output is a single character.  We created around P total number of input/output pairs  (for general step size M we create around ceil(P/M) pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_4'></a>\n",
    "\n",
    "Now its time for you to window the input time series as described above! \n",
    "\n",
    "**TODO:** Create a function that runs a sliding window along the input text and creates associated input/output pairs.  A skeleton function has been provided for you.  Note that this function should input a) the text  b) the window size and c) the step size, and return the input/output sequences.  Note: the return items should be *lists* - not numpy arrays.\n",
    "\n",
    "(remember to copy your completed function into the script *my_answers.py* function titled *window_transform_text* before submitting your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: implement window_transform_series in my_answers.py\n",
    "from my_answers import window_transform_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function complete we can now use it to produce input/output pairs!  We employ the function in the next cell, where the window_size = 50 and step_size = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 5\n",
    "inputs, outputs = window_transform_text(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print out a few input/output pairs to verify that we have made the right sort of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = e eclipses and predominates the whole of her sex. it was not that he felt any emotion akin to love f\n",
      "output = o\n",
      "--------------\n",
      "input = er excellent for drawing the veil from men s motives and actions. but for the trained reasoner to ad\n",
      "output = m\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[2])\n",
    "print('output = ' + outputs[2])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[100])\n",
    "print('output = ' + outputs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114095"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114095"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4  Wait, what kind of problem is text generation again?\n",
    "\n",
    "In part 1 of this notebook we used the same pre-processing technique - the sliding window - to produce a set of training input/output pairs to tackle the problem of time series prediction *by treating the problem as one of regression*.  So what sort of problem do we have here now, with text generation?  Well, the time series prediction was a regression problem because the output (one value of the time series) was a continuous value.  Here - for character-by-character text generation - each output is a *single character*.  This isn't a continuous value - but a distinct class - therefore **character-by-character text generation is a classification problem**.  \n",
    "\n",
    "How many classes are there in the data?  Well, the number of classes is equal to the number of unique characters we have to predict!  How many of those were there in our dataset again?  Lets print out the value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 33 unique characters\n",
      "and these characters are \n",
      "[' ', '!', ',', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique characters in the dataset\n",
    "chars = sorted(list(set(text)))\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")\n",
    "print ('and these characters are ')\n",
    "print (chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rockin' - so we have a multiclass classification problem on our hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5  One-hot encoding characters\n",
    "\n",
    "The last issue we have to deal with is representing our text data as numerical data so that we can use it as an input to a neural network. One of the conceptually simplest ways of doing this is via a 'one-hot encoding' scheme.  Here's how it works.\n",
    "\n",
    "We transform each character in our inputs/outputs into a vector with length equal to the number of unique characters in our text.  This vector is all zeros except one location where we place a 1 - and this location is unique to each character type.  e.g., we transform 'a', 'b', and 'c' as follows\n",
    "\n",
    "$$a\\longleftarrow\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,\\,\\,b\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right]\\,\\,\\,\\,\\,c\\longleftarrow\\left[\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\vdots\\\\\n",
    "0\\\\\n",
    "0 \n",
    "\\end{array}\\right]\\cdots$$\n",
    "\n",
    "where each vector has 32 entries (or in general: number of entries = number of unique characters in text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first practical step towards doing this one-hot encoding is to form a dictionary mapping each unique character to a unique integer, and one dictionary to do the reverse mapping.  We can then use these dictionaries to quickly make our one-hot encodings, as well as re-translate (from integers to characters) the results of our trained RNN classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can transform our input/output pairs - consisting of characters - to equivalent input/output pairs made up of one-hot encoded vectors.  In the next cell we provide a function for doing just this: it takes in the raw character input/outputs and returns their numerical versions.  In particular the numerical input is given as $\\bf{X}$, and numerical output is given as the $\\bf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text, window_size, step_size):\n",
    "    # number of unique chars\n",
    "    chars = sorted(list(set(text)))\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and transform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        y[i, chars_to_indices[outputs[i]]] = 1\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the one-hot encoding function by activating the cell below and transform our input/output pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 180 ms, total: 3.08 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use your function\n",
    "window_size = 100\n",
    "step_size = 5\n",
    "X,y = encode_io_pairs(text,window_size,step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_5'></a>\n",
    "\n",
    "## 2.6 Setting up our RNN\n",
    "\n",
    "With our dataset loaded and the input/output pairs extracted / transformed we can now begin setting up our RNN for training.  Again we will use Keras to quickly build a single hidden layer RNN - where our hidden layer consists of LSTM modules.\n",
    "\n",
    "Time to get to work: build a 3 layer RNN model of the following specification\n",
    "\n",
    "- layer 1 should be an LSTM module with 200 hidden units --> note this should have input_shape = (window_size,len(chars)) where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 2 should be a linear module, fully connected, with len(chars) hidden units --> where len(chars) = number of unique characters in your cleaned text\n",
    "- layer 3 should be a softmax activation ( since we are solving a *multiclass classification*)\n",
    "- Use the **categorical_crossentropy** loss \n",
    "\n",
    "This network can be constructed using just a few lines - as with the RNN network you made in part 1 of this notebook.  See e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LSTM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import keras\n",
    "import random\n",
    "\n",
    "# TODO implement build_part2_RNN in my_answers.py\n",
    "from my_answers import build_part2_RNN\n",
    "\n",
    "model = build_part2_RNN(window_size, len(chars))\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7  Training our RNN model for text generation\n",
    "\n",
    "With our RNN setup we can now train it!  Lets begin by trying it out on a small subset of the larger version.  In the next cell we take the first 10,000 input/output pairs from our training database to learn on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a small subset of our input/output pairs\n",
    "Xsmall = X[:10000,:,:]\n",
    "ysmall = y[:10000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets fit our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10000/10000 [==============================] - 5s - loss: 3.0364     \n",
      "Epoch 2/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.8900     \n",
      "Epoch 3/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.8701     \n",
      "Epoch 4/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.8348     \n",
      "Epoch 5/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.7791     \n",
      "Epoch 6/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.7020     \n",
      "Epoch 7/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.6308     \n",
      "Epoch 8/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.5675     \n",
      "Epoch 9/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.5115     \n",
      "Epoch 10/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.4569     \n",
      "Epoch 11/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.4204     \n",
      "Epoch 12/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.3790     \n",
      "Epoch 13/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.3434     \n",
      "Epoch 14/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.3110     \n",
      "Epoch 15/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.2835     \n",
      "Epoch 16/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.2616     \n",
      "Epoch 17/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.2361     \n",
      "Epoch 18/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.2148     \n",
      "Epoch 19/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1925     \n",
      "Epoch 20/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1783     \n",
      "Epoch 21/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1544     \n",
      "Epoch 22/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1362     \n",
      "Epoch 23/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1195     \n",
      "Epoch 24/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.1022     \n",
      "Epoch 25/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.0850     \n",
      "Epoch 26/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.0603     \n",
      "Epoch 27/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.0512     \n",
      "Epoch 28/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.0244     \n",
      "Epoch 29/40\n",
      "10000/10000 [==============================] - 4s - loss: 2.0078     \n",
      "Epoch 30/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.9912     \n",
      "Epoch 31/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.9709     \n",
      "Epoch 32/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.9521     \n",
      "Epoch 33/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.9285     \n",
      "Epoch 34/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.9120     \n",
      "Epoch 35/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.8939     \n",
      "Epoch 36/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.8643     \n",
      "Epoch 37/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.8487     \n",
      "Epoch 38/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.8216     \n",
      "Epoch 39/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.7990     \n",
      "Epoch 40/40\n",
      "10000/10000 [==============================] - 4s - loss: 1.7684     \n",
      "CPU times: user 3min 56s, sys: 34.6 s, total: 4min 30s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "model.fit(Xsmall, ysmall, batch_size=500, epochs=40, verbose=1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_small_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we make a given number of predictions (characters) based on this fitted model?   \n",
    "\n",
    "First we predict the next character after following any chunk of characters in the text of length equal to our chosen window size.  Then we remove the first character in our input sequence and tack our prediction onto the end.  This gives us a slightly changed sequence of inputs that still has length equal to the size of our window.  We then feed in this updated input sequence into the model to predict the another character.  Together then we have two predicted characters following our original input sequence.  Repeating this process N times gives us N predicted characters.\n",
    "\n",
    "In the next Python cell we provide you with a completed function that does just this - it makes predictions when given a) a trained RNN model, b) a subset of (window_size) characters from the text, and c) a number of characters to predict (to follow our input subset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses trained model to predict a desired number of future characters\n",
    "def predict_next_chars(model,input_chars,num_to_predict):     \n",
    "    # create output\n",
    "    predicted_chars = ''\n",
    "    for i in range(num_to_predict):\n",
    "        # convert this round's predicted characters to numerical input    \n",
    "        x_test = np.zeros((1, window_size, len(chars)))\n",
    "        for t, char in enumerate(input_chars):\n",
    "            x_test[0, t, chars_to_indices[char]] = 1.\n",
    "\n",
    "        # make this round's prediction\n",
    "        test_predict = model.predict(x_test,verbose = 0)[0]\n",
    "\n",
    "        # translate numerical prediction back to characters\n",
    "        r = np.argmax(test_predict)                           # predict class of each test input\n",
    "        d = indices_to_chars[r] \n",
    "\n",
    "        # update predicted_chars and input\n",
    "        predicted_chars+=d\n",
    "        input_chars+=d\n",
    "        input_chars = input_chars[1:]\n",
    "    return predicted_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TODO_6'></a>\n",
    "\n",
    "With your trained model try a few subsets of the complete text as input - note the length of each must be exactly equal to the window size.  For each subset use the function above to predict the next 100 characters that follow each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "erament was to introduce a distracting factor which might throw a doubt upon all his mental results.\"\n",
      "\n",
      "predicted chars = \n",
      " whith a sare the her soug the mand he hor sound hom se the wis the mere the sere the ment of the ma\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "rament was to introduce a distracting factor which might throw a doubt upon all his mental results. \"\n",
      "\n",
      "predicted chars = \n",
      "whith a sare the her soug the mand he hor sound hom se the wis the mere the sere the ment of the man\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ament was to introduce a distracting factor which might throw a doubt upon all his mental results. g\"\n",
      "\n",
      "predicted chars = \n",
      "he has the mand he hor sound hom se the coust of the sore the cound ho mes llled ho mas the man the \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ment was to introduce a distracting factor which might throw a doubt upon all his mental results. gr\"\n",
      "\n",
      "predicted chars = \n",
      "emas longed ho mas llled ho mas the man the soug hom se the sout of the mas in whis s ou that the wa\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ent was to introduce a distracting factor which might throw a doubt upon all his mental results. gri\"\n",
      "\n",
      "predicted chars = \n",
      "me hole the dist on the sere the mand he has the mand he hous the mand he hor se pound hom the sout \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "nt was to introduce a distracting factor which might throw a doubt upon all his mental results. grit\"\n",
      "\n",
      "predicted chars = \n",
      "h a sore the her sout of the mas when i has the lang he mas the mas the mand he hous the pare the to\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "t was to introduce a distracting factor which might throw a doubt upon all his mental results. grit \"\n",
      "\n",
      "predicted chars = \n",
      "se pore the sert of the mast whe her in wall and the mand he hour the pore the tore the core the cou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " was to introduce a distracting factor which might throw a doubt upon all his mental results. grit i\"\n",
      "\n",
      "predicted chars = \n",
      "n to the coust of the sound hom se the cound ho mes the mas the mand he has ingard he hor sout the m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in\"\n",
      "\n",
      "predicted chars = \n",
      " to the coust of the sound hom se the cound ho mes the mas the mand he has ingard he hor sout the ma\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "as to introduce a distracting factor which might throw a doubt upon all his mental results. grit in \"\n",
      "\n",
      "predicted chars = \n",
      "to the coust of the sound hom se the cound ho mes the mas the mand he has ingard he hor sout the man\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "s to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a\"\n",
      "\n",
      "predicted chars = \n",
      " dore the sert in the sert of the mast be mas the mas the mand he has the wall the dout mas the wis \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a \"\n",
      "\n",
      "predicted chars = \n",
      "dore the sert in the sert of the mast be mas the mas the mand he has the wall the dout mas the wis t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a s\"\n",
      "\n",
      "predicted chars = \n",
      "ore the sere the mand he har was he mas the mas the mand he hous the mand he hor soug the mest of th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "o introduce a distracting factor which might throw a doubt upon all his mental results. grit in a se\"\n",
      "\n",
      "predicted chars = \n",
      "re the sore the mand whe has the wall and the mand he hous the mand he hor soug the mest of the sing\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sen\"\n",
      "\n",
      "predicted chars = \n",
      "t wis lome the the wand ho mes llled ho mas the man the sore the cound ho mes llled ho mas the man t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sens\"\n",
      "\n",
      "predicted chars = \n",
      " wing ho mes the mas the mas the mas the mand he has been the rest on the sout the sere the core the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ntroduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensi\"\n",
      "\n",
      "predicted chars = \n",
      "ted his the wis whin the sing wall so me the the war the mand he has the wall of the mast and he his\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "troduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensit\"\n",
      "\n",
      "predicted chars = \n",
      "ed his the wis whin the sing wall so me the the war the mand he has the wall of the mast and he his \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "roduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensiti\"\n",
      "\n",
      "predicted chars = \n",
      "g har the wis on the sert of the sout of the mas when i soo mall the sert of mome the cous the mand \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "oduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitiv\"\n",
      "\n",
      "predicted chars = \n",
      "e hom the sere the cound ho mes llled ho mas the man the soug hom se the sout of the mas in whis s o\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "duce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive\"\n",
      "\n",
      "predicted chars = \n",
      " hom the sere the cound ho mes llled ho mas the man the soug hom se the sout of the mas in whis s ou\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "uce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive \"\n",
      "\n",
      "predicted chars = \n",
      "hom the sere the cound ho mes llled ho mas the man the soug hom se the sout of the mas in whis s ou \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive i\"\n",
      "\n",
      "predicted chars = \n",
      "n the mes when i has the lang the mand he har in wall be the mand he hor the pare the tore the mand \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "e a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive in\"\n",
      "\n",
      "predicted chars = \n",
      " the mes when i has the lang the mand he har in wall be the mand he hor the pare the tore the mand h\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive ins\"\n",
      "\n",
      "predicted chars = \n",
      "tere the sore the mand he has been the rest on the sore the core the core the cound ho mes llled ho \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive inst\"\n",
      "\n",
      "predicted chars = \n",
      "ere the sore the mand he has been the rest on the sore the core the core the cound ho mes llled ho m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instr\"\n",
      "\n",
      "predicted chars = \n",
      "ent whis ho win wish a d and wall and the mand he hous the mand he hor seen the mest the sis of mome\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instru\"\n",
      "\n",
      "predicted chars = \n",
      "tt of the core the cound ho mas the har sound hom so the his the sound hom se pound hom se the cound\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "istracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrum\"\n",
      "\n",
      "predicted chars = \n",
      "t you hom my wall so the sing the mest on the sing was the sere the mand he hor mas the man the sore\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "stracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrume\"\n",
      "\n",
      "predicted chars = \n",
      " y of the mist on the sing and sere the core the mand he has the wall of the mast and he his wand ho\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "tracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrumen\"\n",
      "\n",
      "predicted chars = \n",
      " s of the ming what s and wall and he mast on the sore the mand whe has the wall and ser in the rest\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "racting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument\"\n",
      "\n",
      "predicted chars = \n",
      " sher in wis lone the dert on the sout the mand whe has the wall and the mand he hour the pore the t\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "acting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument,\"\n",
      "\n",
      "predicted chars = \n",
      " and wing his wine the core the cound ho mes llled ho mas the man the sore the cound ho mes the mas \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "cting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, \"\n",
      "\n",
      "predicted chars = \n",
      "and wing his wine the core the cound ho mes llled ho mas the man the sore the cound ho mes the mas t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, o\"\n",
      "\n",
      "predicted chars = \n",
      "f the ming whin the sere wall and the mand he has the wall of the mast and he his wand hom se the wa\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ing factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or\"\n",
      "\n",
      "predicted chars = \n",
      " whis lone the cound ho mes the mas the mand he has ingard he hor sout the man the has the wall and \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ng factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or \"\n",
      "\n",
      "predicted chars = \n",
      "whis lone the cound ho mes the mas the mand he has ingard he hor sout the man the has the wall and h\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "g factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a\"\n",
      "\n",
      "predicted chars = \n",
      " har was he chat bure the rowe the core the core the core the cound ho mes llled ho mas the man the \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a \"\n",
      "\n",
      "predicted chars = \n",
      "har was he chat bure the rowe the core the core the core the cound ho mes llled ho mas the man the s\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a c\"\n",
      "\n",
      "predicted chars = \n",
      "are the cound hom se the cound ho mes the har so wall so me the the sout of the mas when i soo mall \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "actor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a cr\"\n",
      "\n",
      "predicted chars = \n",
      "imin lofre the wand he has the mand he hous the mand he hor seen the mest the sis of mome the sore t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ctor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a cra\"\n",
      "\n",
      "predicted chars = \n",
      "in lllest the the wand ho mes lled to me the the sound hom se the cound ho mes the har so wall so me\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "tor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crac\"\n",
      "\n",
      "predicted chars = \n",
      "ine hom sere the hand of the man the sere the mand he hous the mand he hor se pound hom the sout of \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "or which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack\"\n",
      "\n",
      "predicted chars = \n",
      "ing hom sere the her oug the man the her and wall so me the the sout of the mas when ho mas then in \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "r which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack \"\n",
      "\n",
      "predicted chars = \n",
      "in the sert in the sere the mand he har the wall and the mand he hour the pore the tore the cound ho\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack i\"\n",
      "\n",
      "predicted chars = \n",
      "n the sert in the sere the mand he har the wall and the mand he hour the pore the tore the cound ho \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in\"\n",
      "\n",
      "predicted chars = \n",
      " the sert in the sere the mand he har the wall and the mand he hour the pore the tore the cound ho m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "hich might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in \"\n",
      "\n",
      "predicted chars = \n",
      "the sert in the sere the mand he har the wall and the mand he hour the pore the tore the cound ho me\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ich might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in o\"\n",
      "\n",
      "predicted chars = \n",
      "f the serting hom she chat in the sere the mand he har in wall be the mand he hor the pare the tore \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ch might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in on\"\n",
      "\n",
      "predicted chars = \n",
      " the tore the hous the mand he hor seen the mest the sis of mome the sore the mant the sere the mand\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "h might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one\"\n",
      "\n",
      "predicted chars = \n",
      " sore the her was he mas llled the the shat the mest on the sing the mand he hou d and wall be the m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one \"\n",
      "\n",
      "predicted chars = \n",
      "sore the her was he mas llled the the shat the mest on the sing the mand he hou d and wall be the ma\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one o\"\n",
      "\n",
      "predicted chars = \n",
      "f the mant whe her a dare and ser in the sert of mas the her was hom se the the sore the mont of the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ight throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of\"\n",
      "\n",
      "predicted chars = \n",
      " the mant whe her a dare and ser in the sert of mas the her was hom se the the sore the mont of the \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ght throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of \"\n",
      "\n",
      "predicted chars = \n",
      "the mant whe her a dare and ser in the sert of mas the her was hom se the the sore the mont of the m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ht throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of h\"\n",
      "\n",
      "predicted chars = \n",
      "e mast but ho mas then i has tore the core the cound ho mes llled ho mas the man the soug hom se the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "t throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of hi\"\n",
      "\n",
      "predicted chars = \n",
      "m sould ho mes llled ho mas the man the sore the cound ho mes llled ho mas the man the sore the coun\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his\"\n",
      "\n",
      "predicted chars = \n",
      " wall the dered in the sert the mand whe has been the mest the mas the mand he has been the rest on \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his \"\n",
      "\n",
      "predicted chars = \n",
      "wall the dered in the sert the mand whe has been the mest the mas the mand he has been the rest on t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "hrow a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his o\"\n",
      "\n",
      "predicted chars = \n",
      "f the mest re the serting and the sing whin the sere win the sert wan the sing was the sere the mand\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "row a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his ow\"\n",
      "\n",
      "predicted chars = \n",
      " the cour the sere the reat on the mand whin s ow the louth what s and wall so man the sore the mand\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ow a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own\"\n",
      "\n",
      "predicted chars = \n",
      " hom se the wing ho mes llled of the mant re hou d ou d and bere the the sout of the mas when i was \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "w a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own \"\n",
      "\n",
      "predicted chars = \n",
      "hom se the wing ho mes llled of the mant re hou d ou d and bere the the sout of the mas when i was t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own h\"\n",
      "\n",
      "predicted chars = \n",
      "om se the wing ho mes llled of the mant re hou d ou d and bere the the sout of the mas when i was th\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own hi\"\n",
      "\n",
      "predicted chars = \n",
      "s the sing whin the dowe the cound ho mes llled ho mas the man the sore the cound ho mes the mas the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own hig\"\n",
      "\n",
      "predicted chars = \n",
      " s an the sing the mand he hou d and wall be the mand he hor the pare the tore the mand he has the w\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high\"\n",
      "\n",
      "predicted chars = \n",
      " the wis lone the dout of the mas when i was the lader wh the s out mase the her of the mant you has\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "oubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high \"\n",
      "\n",
      "predicted chars = \n",
      "the wis lone the dout of the mas when i was the lader wh the s out mase the her of the mant you has \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high p\"\n",
      "\n",
      "predicted chars = \n",
      "our the hes ou the mand whe har the wall and the mand he hour the pore the tore the cound ho mes lll\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "bt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high po\"\n",
      "\n",
      "predicted chars = \n",
      "ur the hes ou the mand whe har the wall and the mand he hour the pore the tore the cound ho mes llle\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "t upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high pow\"\n",
      "\n",
      "predicted chars = \n",
      "e the cound ho mes the mas the mand he has ingard he hor sout the man the has the wall and he mas th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high powe\"\n",
      "\n",
      "predicted chars = \n",
      " the cound ho mes the mas the mand he has ingard he hor sout the man the has the wall and he mas the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power\"\n",
      "\n",
      "predicted chars = \n",
      " in the sert wat he she wall and ser in the sore the mand he has been the mest the mas the mand he h\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "pon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power \"\n",
      "\n",
      "predicted chars = \n",
      "in the sert wat he she wall and ser in the sore the mand he has been the mest the mas the mand he ha\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "on all his mental results. grit in a sensitive instrument, or a crack in one of his own high power l\"\n",
      "\n",
      "predicted chars = \n",
      "ome so the sout ho mes the has the wing ho mes llled ho mas the man the sore the cound ho mes llled \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "n all his mental results. grit in a sensitive instrument, or a crack in one of his own high power le\"\n",
      "\n",
      "predicted chars = \n",
      " the serting to me the wis was the man the has the mand he hous the pare the cound ho mas the his wa\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " all his mental results. grit in a sensitive instrument, or a crack in one of his own high power len\"\n",
      "\n",
      "predicted chars = \n",
      "t on the sing har she wis lome the the war the long the mand he hor soug the mest of the sing was th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lens\"\n",
      "\n",
      "predicted chars = \n",
      " on the sort of the mont whe has the wall and ser in the rest on the sout hou s and wall and whin th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ll his mental results. grit in a sensitive instrument, or a crack in one of his own high power lense\"\n",
      "\n",
      "predicted chars = \n",
      " to the sout ho mas the har sound hom so the wist on the serting hom sould hom se the cound ho mes t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "l his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses\"\n",
      "\n",
      "predicted chars = \n",
      " on the sore the cound ho mes llled ho mas the man the sore the cound ho mes llled ho mas the man th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses,\"\n",
      "\n",
      "predicted chars = \n",
      " and in the her was he mas llled the the shat the mest on the sing the mand he hou d and wall be the\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, \"\n",
      "\n",
      "predicted chars = \n",
      "and in the her was he mas llled the the shat the mest on the sing the mand he hou d and wall be the \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "is mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, w\"\n",
      "\n",
      "predicted chars = \n",
      "ith a s an the wist on the man the has the wall of the mast and he his wand hom se the war the rest \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "s mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, wo\"\n",
      "\n",
      "predicted chars = \n",
      " mas the the sound hom se the cound ho mes the har so wall so me the the sout of the mas when i soo \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, wou\"\n",
      "\n",
      "predicted chars = \n",
      "ld he hous bound hom the sout hou s and whin the sere wall so the sout the mest on the sing and sere\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, woul\"\n",
      "\n",
      "predicted chars = \n",
      "d he hous bound hom the sout hou s and whin the sere wall so the sout the mest on the sing and sere \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would\"\n",
      "\n",
      "predicted chars = \n",
      " he hous bound hom the sout hou s and whin the sere wall so the sout the mest on the sing and sere t\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ntal results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would \"\n",
      "\n",
      "predicted chars = \n",
      "he hous bound hom the sout hou s and whin the sere wall so the sout the mest on the sing and sere th\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "tal results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would n\"\n",
      "\n",
      "predicted chars = \n",
      "ot the ling what the war in what s and in the sert of the mast on the sing was the d ous hous the to\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "al results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would no\"\n",
      "\n",
      "predicted chars = \n",
      "t the ling what the war in what s and in the sert of the mast on the sing was the d ous hous the tor\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "l results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not\"\n",
      "\n",
      "predicted chars = \n",
      " the ling what the war in what s and in the sert of the mast on the sing was the d ous hous the tore\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      " results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not \"\n",
      "\n",
      "predicted chars = \n",
      "the ling what the war in what s and in the sert of the mast on the sing was the d ous hous the tore \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not b\"\n",
      "\n",
      "predicted chars = \n",
      "e and and in the sere the mand he has the mand he hous the mand he hor se pound hom the sout of the \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "esults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be\"\n",
      "\n",
      "predicted chars = \n",
      " and and in the sere the mand he has the mand he hous the mand he hor se pound hom the sout of the m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "sults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be \"\n",
      "\n",
      "predicted chars = \n",
      "and and in the sere the mand he has the mand he hous the mand he hor se pound hom the sout of the ma\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be m\"\n",
      "\n",
      "predicted chars = \n",
      "as llled t on the the the moun the sore the ront of the man the her and and and in the sere the mand\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "input chars = \n",
      "lts. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be mo\"\n",
      "\n",
      "predicted chars = \n",
      "ne she mes of the mast on the sing was the d ous hous the tore the cound ho mas the wis the mest on \"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "ts. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be mor\"\n",
      "\n",
      "predicted chars = \n",
      "e she cous the man the har was he man the sere the mand the sore the cound ho mes llled ho mas the m\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      "s. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more\"\n",
      "\n",
      "predicted chars = \n",
      " she cous the man the har was he man the sere the mand the sore the cound ho mes llled ho mas the ma\"\n",
      "\n",
      "------------------\n",
      "input chars = \n",
      ". grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more \"\n",
      "\n",
      "predicted chars = \n",
      "she cous the man the har was he man the sere the mand the sore the cound ho mes llled ho mas the man\"\n",
      "\n",
      "CPU times: user 5min 17s, sys: 0 ns, total: 5min 17s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = np.arange(666, 666+100)\n",
    "\n",
    "# load in weights\n",
    "model.load_weights('model_weights/best_RNN_small_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    print('------------------')\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks ok, but not great.  Now lets try the same experiment with a larger chunk of the data - with the first 100,000 input/output pairs.  \n",
    "\n",
    "Tuning RNNs for a typical character dataset like the one we will use here is a computationally intensive endeavour and thus timely on a typical CPU.  Using a reasonably sized cloud-based GPU can speed up training by a factor of 10.  Also because of the long training time it is highly recommended that you carefully write the output of each step of your process to file.  This is so that all of your results are saved even if you close the web browser you're working out of, as the processes will continue processing in the background but variables/output in the notebook system will not update when you open it again.\n",
    "\n",
    "In the next cell we show you how to create a text file in Python and record data to it.  This sort of setup can be used to record your final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is only a test \\nthe value of x is 2\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### A simple way to write output to file\n",
    "f = open('my_test_output.txt', 'w')              # create an output file to write too\n",
    "f.write('this is only a test ' + '\\n')           # print some output text\n",
    "x = 2\n",
    "f.write('the value of x is ' + str(x) + '\\n')    # record a variable value\n",
    "f.close()     \n",
    "\n",
    "# print out the contents of my_test_output.txt\n",
    "f = open('my_test_output.txt', 'r')              # create an output file to write too\n",
    "f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this recording devices we can now more safely perform experiments on larger portions of the text.  In the next cell we will use the first 100,000 input/output pairs to train our RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fit our model to the dataset, then generate text using the trained model in precisely the same generation method applied before on the small dataset.\n",
    "\n",
    "**Note:** your generated words should be - by and large - more realistic than with the small dataset, but you won't be able to generate perfect English sentences even with this amount of data.  A rule of thumb: your model is working well if you generate sentences that largely contain real English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100000/100000 [==============================] - 45s - loss: 2.0142    \n",
      "Epoch 2/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.9241    \n",
      "Epoch 3/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.8619    \n",
      "Epoch 4/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.8083    \n",
      "Epoch 5/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.7625    \n",
      "Epoch 6/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.7212    \n",
      "Epoch 7/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.6823    \n",
      "Epoch 8/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.6455    \n",
      "Epoch 9/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.6100    \n",
      "Epoch 10/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.5770    \n",
      "Epoch 11/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.5445    \n",
      "Epoch 12/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.5134    \n",
      "Epoch 13/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.4834    \n",
      "Epoch 14/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.4545    \n",
      "Epoch 15/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.4251    \n",
      "Epoch 16/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.3964    \n",
      "Epoch 17/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.3686    \n",
      "Epoch 18/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.3390    \n",
      "Epoch 19/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.3116    \n",
      "Epoch 20/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.2830    \n",
      "Epoch 21/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.2561    \n",
      "Epoch 22/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.2277    \n",
      "Epoch 23/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.1998    \n",
      "Epoch 24/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.1713    \n",
      "Epoch 25/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.1446    \n",
      "Epoch 26/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.1184    \n",
      "Epoch 27/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.0907    \n",
      "Epoch 28/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.0637    \n",
      "Epoch 29/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.0381    \n",
      "Epoch 30/30\n",
      "100000/100000 [==============================] - 45s - loss: 1.0128    \n",
      "CPU times: user 29min 28s, sys: 4min 6s, total: 33min 35s\n",
      "Wall time: 22min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# a small subset of our input/output pairs\n",
    "Xlarge = X[:100000,:,:]\n",
    "ylarge = y[:100000,:]\n",
    "\n",
    "# TODO: fit to our larger dataset\n",
    "model.fit(Xlarge, ylarge, batch_size=500, epochs=30, verbose=1)\n",
    "\n",
    "# save weights\n",
    "model.save_weights('model_weights/best_RNN_large_textdata_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "erament was to introduce a distracting factor which might throw a doubt upon all his mental results.\"\n",
      "\n",
      "predicted chars = \n",
      " he had been from it was a caunt face. and he would sit in one harrstance of the sugrose s case. the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "rament was to introduce a distracting factor which might throw a doubt upon all his mental results. \"\n",
      "\n",
      "predicted chars = \n",
      "he had been from it was a caunt face. and he would sit in one harrstance of the sugrose s case. then\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ament was to introduce a distracting factor which might throw a doubt upon all his mental results. g\"\n",
      "\n",
      "predicted chars = \n",
      "o soll you stent to love to be ad officed to her fact. it was no down the state of the glades and sa\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ment was to introduce a distracting factor which might throw a doubt upon all his mental results. gr\"\n",
      "\n",
      "predicted chars = \n",
      "eathered of the lady strelt miss which was all that of is as a stap came. which asked hearty to grea\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ent was to introduce a distracting factor which might throw a doubt upon all his mental results. gri\"\n",
      "\n",
      "predicted chars = \n",
      "stlled nothing mad turn i have leaden to me sump a see upon the state. he was been to see that i was\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "nt was to introduce a distracting factor which might throw a doubt upon all his mental results. grit\"\n",
      "\n",
      "predicted chars = \n",
      "h list the sellecaning case and lady upon me was of a presect of a plaie who had let we spond but th\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "t was to introduce a distracting factor which might throw a doubt upon all his mental results. grit \"\n",
      "\n",
      "predicted chars = \n",
      "lift he strack that the may we a ple as when i have to do bot there the fands and down a park agat t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " was to introduce a distracting factor which might throw a doubt upon all his mental results. grit i\"\n",
      "\n",
      "predicted chars = \n",
      "s and the street of the marriage was so strepsed in the door. it was no down that he was not into my\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "was to introduce a distracting factor which might throw a doubt upon all his mental results. grit in\"\n",
      "\n",
      "predicted chars = \n",
      " the sublle san should be in mose that i could down to have been the off it was to the bounds of the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "as to introduce a distracting factor which might throw a doubt upon all his mental results. grit in \"\n",
      "\n",
      "predicted chars = \n",
      "the sublle san should be in mose that i could down to have been the off it was to the bounds of the \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "s to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a\"\n",
      "\n",
      "predicted chars = \n",
      "nd the present some offer which i had to dear that i have to do bo hore that i could not have ment a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a \"\n",
      "\n",
      "predicted chars = \n",
      "presust and as a come out of hourd he dood up our very such one of the stange so care in a comple an\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "to introduce a distracting factor which might throw a doubt upon all his mental results. grit in a s\"\n",
      "\n",
      "predicted chars = \n",
      "ome of the start. he had not case the door he dadged in the housh when you see memery letters, i am \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "o introduce a distracting factor which might throw a doubt upon all his mental results. grit in a se\"\n",
      "\n",
      "predicted chars = \n",
      "at the matter was a could seer his here can to some him. the father was a cond. it was on me. and i \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sen\"\n",
      "\n",
      "predicted chars = \n",
      "t that the day laster down the blad a marraw which we had nother of the sut and a she fach. his now \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "introduce a distracting factor which might throw a doubt upon all his mental results. grit in a sens\"\n",
      "\n",
      "predicted chars = \n",
      " that the passe of the manther less and marred that the stape with my stapped, and she was about to \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ntroduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensi\"\n",
      "\n",
      "predicted chars = \n",
      "on of the manters which i stark to my him will not in a butter, and i was not insain to him. he was \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "troduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensit\"\n",
      "\n",
      "predicted chars = \n",
      "ion of a shall garded my had wather streeting lightse which have been sead allass. i have alled ever\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "roduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensiti\"\n",
      "\n",
      "predicted chars = \n",
      "on of a shall garded my had wather streeting lightse which have been sead allass. i have alled ever \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "oduce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitiv\"\n",
      "\n",
      "predicted chars = \n",
      "e with a compartion was dond to return to his fater and such spope sime of the sing. it was no downi\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "duce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive\"\n",
      "\n",
      "predicted chars = \n",
      " with a compartion was dond to return to his fater and such spope sime of the sing. it was no downit\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "uce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive \"\n",
      "\n",
      "predicted chars = \n",
      "with a compartion was dond to return to his fater and such spope sime of the sing. it was no downith\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ce a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive i\"\n",
      "\n",
      "predicted chars = \n",
      "n the suture sime said he may have alled the dread and she pelled most that she was a come for whis \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "e a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive in\"\n",
      "\n",
      "predicted chars = \n",
      " the suture sime said he may have alled the dread and she pelled most that she was a come for whis i\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive ins\"\n",
      "\n",
      "predicted chars = \n",
      "ter sempared the looks of the man which we have been see the door that manter will do so to have the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "a distracting factor which might throw a doubt upon all his mental results. grit in a sensitive inst\"\n",
      "\n",
      "predicted chars = \n",
      "er sempared the looks of the man which we have been see the door that manter will do so to have the \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instr\"\n",
      "\n",
      "predicted chars = \n",
      "ing of the manther with a strung that me bade and shall be a poovession which he had to do bo home t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "distracting factor which might throw a doubt upon all his mental results. grit in a sensitive instru\"\n",
      "\n",
      "predicted chars = \n",
      "ct of the one of the manthor. we shall not hever head to sten, him before had cater on the end a pai\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "istracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrum\"\n",
      "\n",
      "predicted chars = \n",
      "ing my present state our blooke she was a could gaid up the street of the marrait, a shall sook down\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "stracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrume\"\n",
      "\n",
      "predicted chars = \n",
      "n rommort anter sider at the doom a dain that i would see the dee of the sing. it was no down the st\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "tracting factor which might throw a doubt upon all his mental results. grit in a sensitive instrumen\"\n",
      "\n",
      "predicted chars = \n",
      " rommort anter sider at the doom a dain that i would see the dee of the sing. it was no down the sta\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "racting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument\"\n",
      "\n",
      "predicted chars = \n",
      " minessed how to see im no thince of hardly see makers, which she had cater lighted and we have to s\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "acting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument,\"\n",
      "\n",
      "predicted chars = \n",
      " it would not be a prove to the window out his face in a care to dear folmes and her with a comple o\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "cting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, \"\n",
      "\n",
      "predicted chars = \n",
      "it would not be a prove to the window out his face in a care to dear folmes and her with a comple of\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ting factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, o\"\n",
      "\n",
      "predicted chars = \n",
      "n the sigge of the manthreal caster of the manting was a curree upon my companion which he had to pe\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ing factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or\"\n",
      "\n",
      "predicted chars = \n",
      " it was a low little pape which i had to do bo had been the street. he woo day net the sime shoute o\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ng factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or \"\n",
      "\n",
      "predicted chars = \n",
      "it was a low little pape which i had to do bo had been the street. he woo day net the sime shoute on\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "g factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a\"\n",
      "\n",
      "predicted chars = \n",
      " man who was closed it mater at mose for and such a comp of the house. it was no his. we shall be no\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a \"\n",
      "\n",
      "predicted chars = \n",
      "man who was closed it mater at mose for and such a comp of the house. it was no his. we shall be not\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "factor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a c\"\n",
      "\n",
      "predicted chars = \n",
      "rester and daye add and she had been leare it all as which i had gen side a poost that there was a r\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "actor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a cr\"\n",
      "\n",
      "predicted chars = \n",
      "ester and daye add and she had been leare it all as which i had gen side a poost that there was a ro\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ctor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a cra\"\n",
      "\n",
      "predicted chars = \n",
      "se to so. inderedto steen, said he. i was not inserved to have been the most than she was a matter d\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "tor which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crac\"\n",
      "\n",
      "predicted chars = \n",
      "k to his was a corver. it is the langer of the mantwhere which has that here was a wasted but in sho\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "or which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack\"\n",
      "\n",
      "predicted chars = \n",
      " to his was a corver. it is the langer of the mantwhere which has that here was a wasted but in shou\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "r which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack \"\n",
      "\n",
      "predicted chars = \n",
      "to his was a corver. it is the langer of the mantwhere which has that here was a wasted but in shour\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack i\"\n",
      "\n",
      "predicted chars = \n",
      " shall came to have a surden be the mote that it was no down to have be no dount that a low let upon\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "which might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in\"\n",
      "\n",
      "predicted chars = \n",
      " had last upon my hand so expected the revire a man who had looked down the doorsow of them, and she\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "hich might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in \"\n",
      "\n",
      "predicted chars = \n",
      "had last upon my hand so expected the revire a man who had looked down the doorsow of them, and she \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ich might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in o\"\n",
      "\n",
      "predicted chars = \n",
      "ne and the poon sowienabler canding and as a stap to must have and doce to you a very sucted to out \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ch might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in on\"\n",
      "\n",
      "predicted chars = \n",
      "e and the poon sowienabler canding and as a stap to must have and doce to you a very sucted to out n\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "h might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one\"\n",
      "\n",
      "predicted chars = \n",
      " and the poon sowienabler canding and as a stap to must have and doce to you a very sucted to out no\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one \"\n",
      "\n",
      "predicted chars = \n",
      "and the poon sowienabler canding and as a stap to must have and doce to you a very sucted to out not\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "might throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one o\"\n",
      "\n",
      "predicted chars = \n",
      "f the windows our dorngar which had been sereated and said he must up in the day station of his hadd\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ight throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of\"\n",
      "\n",
      "predicted chars = \n",
      " the windows our dorngar which had been sereated and said he must up in the day station of his hadd \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ght throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of \"\n",
      "\n",
      "predicted chars = \n",
      "the windows our dorngar which had been sereated and said he must up in the day station of his hadd a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ht throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of h\"\n",
      "\n",
      "predicted chars = \n",
      "er would so, sit in the room. and she hod had been seceed the door it was a muther surd all master d\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "t throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of hi\"\n",
      "\n",
      "predicted chars = \n",
      "s was as was all as no dount that the pall case to have here the door. when he had to do bo have to \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his\"\n",
      "\n",
      "predicted chars = \n",
      " was as was all as no dount that the pall case to have here the door. when he had to do bo have to b\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "throw a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his \"\n",
      "\n",
      "predicted chars = \n",
      "was as was all as no dount that the pall case to have here the door. when he had to do bo have to be\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "hrow a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his o\"\n",
      "\n",
      "predicted chars = \n",
      "wn sigge and a shall s of sow the doorsial been simetion of and the tree that the pappess ago the si\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "row a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his ow\"\n",
      "\n",
      "predicted chars = \n",
      "n sigge and a shall s of sow the doorsial been simetion of and the tree that the pappess ago the sim\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ow a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own\"\n",
      "\n",
      "predicted chars = \n",
      " sigge and a shall s of sow the doorsial been simetion of and the tree that the pappess ago the sime\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "w a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own \"\n",
      "\n",
      "predicted chars = \n",
      "sigge and a shall s of sow the doorsial been simetion of and the tree that the pappess ago the sime \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own h\"\n",
      "\n",
      "predicted chars = \n",
      "is ways. it is a wookse would not have been the lose that i was very stated and save the room a dee \"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "a doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own hi\"\n",
      "\n",
      "predicted chars = \n",
      "s ways. it is a wookse would not have been the lose that i was very stated and save the room a dee t\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own hig\"\n",
      "\n",
      "predicted chars = \n",
      "ht a cereat of shat and a come from him and soce her the office and lide outs. i was very sure to th\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "doubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high\"\n",
      "\n",
      "predicted chars = \n",
      "t a cereat of shat and a come from him and soce her the office and lide outs. i was very sure to the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "oubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high \"\n",
      "\n",
      "predicted chars = \n",
      "and the presert of the motternd with the street so the manters which had been dearing that he is a w\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ubt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high p\"\n",
      "\n",
      "predicted chars = \n",
      "ass an adriss semeng strenting for at the door of the matter. i have no doubt that the edid a sompar\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "bt upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high po\"\n",
      "\n",
      "predicted chars = \n",
      "se be was compance to his fair. i have been seen the door the popies. i should have been sace at the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "t upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high pow\"\n",
      "\n",
      "predicted chars = \n",
      "e of the stang. he had been led an the sime street of the manters which had been seen the dise of th\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high powe\"\n",
      "\n",
      "predicted chars = \n",
      " of the stang. he had been led an the sime street of the manters which had been seen the dise of the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "upon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power\"\n",
      "\n",
      "predicted chars = \n",
      " and the sone of the man who was a statioman of a surden barked with might and a colfed upon my comp\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "pon all his mental results. grit in a sensitive instrument, or a crack in one of his own high power \"\n",
      "\n",
      "predicted chars = \n",
      "and the sone of the man who was a statioman of a surden barked with might and a colfed upon my compa\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "on all his mental results. grit in a sensitive instrument, or a crack in one of his own high power l\"\n",
      "\n",
      "predicted chars = \n",
      "ettered to off he rad hand, have been see the door to the outhere of the manters which had been sere\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "n all his mental results. grit in a sensitive instrument, or a crack in one of his own high power le\"\n",
      "\n",
      "predicted chars = \n",
      "ttered to off he rad hand, have been see the door to the outhere of the manters which had been seree\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " all his mental results. grit in a sensitive instrument, or a crack in one of his own high power len\"\n",
      "\n",
      "predicted chars = \n",
      "g and as it man and me pare to and the door of the sustant of the broke said holmes, and i was a low\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "all his mental results. grit in a sensitive instrument, or a crack in one of his own high power lens\"\n",
      "\n",
      "predicted chars = \n",
      " of a proin sto the steen. i have no doubt that the edid a somparad, and he was sutten in the mose b\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ll his mental results. grit in a sensitive instrument, or a crack in one of his own high power lense\"\n",
      "\n",
      "predicted chars = \n",
      "lf upon and a self carman of she cresed one of the man which we have been seen a last from homman. w\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "l his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses\"\n",
      "\n",
      "predicted chars = \n",
      ", and and we spow the street of the marriage. when i ad the man who had engaged in he has a reas for\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses,\"\n",
      "\n",
      "predicted chars = \n",
      " and and we spow the street of the marriage. when i ad the man who had engaged in he has a reas for \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "his mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, \"\n",
      "\n",
      "predicted chars = \n",
      "and and we spow the street of the marriage. when i ad the man who had engaged in he has a reas for m\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "is mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, w\"\n",
      "\n",
      "predicted chars = \n",
      "hat you have been in the street. i should have been that he was a starlical riss. i have aver seen a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "s mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, wo\"\n",
      "\n",
      "predicted chars = \n",
      "uld be at have heard, and there was not to be a poliess in the street of the marriage. what no your \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, wou\"\n",
      "\n",
      "predicted chars = \n",
      "ld be at have heard, and there was not to be a poliess in the street of the marriage. what no your f\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "mental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, woul\"\n",
      "\n",
      "predicted chars = \n",
      "d be at have heard, and there was not to be a poliess in the street of the marriage. what no your fa\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ental results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would\"\n",
      "\n",
      "predicted chars = \n",
      " be at have heard, and there was not to be a poliess in the street of the marriage. what no your far\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ntal results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would \"\n",
      "\n",
      "predicted chars = \n",
      "be at have heard, and there was not to be a poliess in the street of the marriage. what no your fard\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "tal results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would n\"\n",
      "\n",
      "predicted chars = \n",
      "ot in a sure to my staty. i would not to have headd and she was a marrain greder and she was offed a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "al results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would no\"\n",
      "\n",
      "predicted chars = \n",
      "t in a sure to my staty. i would not to have headd and she was a marrain greder and she was offed an\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "l results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not\"\n",
      "\n",
      "predicted chars = \n",
      " in a sure to my staty. i would not to have headd and she was a marrain greder and she was offed and\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      " results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not \"\n",
      "\n",
      "predicted chars = \n",
      "in a sure to my staty. i would not to have headd and she was a marrain greder and she was offed and \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "results. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not b\"\n",
      "\n",
      "predicted chars = \n",
      "e ad a stard. there was not to be a parte to your father save in the edir grood and the ender of the\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "esults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be\"\n",
      "\n",
      "predicted chars = \n",
      " ad a stard. there was not to be a parte to your father save in the edir grood and the ender of the \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "sults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be \"\n",
      "\n",
      "predicted chars = \n",
      "ad a stard. there was not to be a parte to your father save in the edir grood and the ender of the w\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ults. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be m\"\n",
      "\n",
      "predicted chars = \n",
      "ay hat do bo hoads of the sing. it was no down the state of the greathed to have been the street. it\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "\n",
      "input chars = \n",
      "lts. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be mo\"\n",
      "\n",
      "predicted chars = \n",
      "se be so that there was a reast to geen the shouted on the suge the expestared with my that and of i\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "ts. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be mor\"\n",
      "\n",
      "predicted chars = \n",
      "e than you and erea to the office, and lease to his hands to see in the seppess. whole see hears an \"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      "s. grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more\"\n",
      "\n",
      "predicted chars = \n",
      " than you and erea to the office, and lease to his hands to see in the seppess. whole see hears an a\"\n",
      "\n",
      "-------------------\n",
      "\n",
      "input chars = \n",
      ". grit in a sensitive instrument, or a crack in one of his own high power lenses, would not be more \"\n",
      "\n",
      "predicted chars = \n",
      "than you and erea to the office, and lease to his hands to see in the seppess. whole see hears an al\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: choose an input sequence and use the prediction function in the previous Python cell to predict 100 characters following it\n",
    "# get an appropriately sized chunk of characters from the text\n",
    "start_inds = start_inds  #[]\n",
    "\n",
    "# save output\n",
    "f = open('text_gen_output/RNN_large_textdata_output.txt', 'w')  # create an output file to write too\n",
    "\n",
    "# load weights\n",
    "model.load_weights('model_weights/best_RNN_large_textdata_weights.hdf5')\n",
    "for s in start_inds:\n",
    "    start_index = s\n",
    "    input_chars = text[start_index: start_index + window_size]\n",
    "\n",
    "    # use the prediction function\n",
    "    predict_input = predict_next_chars(model,input_chars,num_to_predict = 100)\n",
    "\n",
    "    # print out input characters\n",
    "    line = '-------------------' + '\\n'\n",
    "    print(line)\n",
    "    f.write(line)\n",
    "\n",
    "    input_line = 'input chars = ' + '\\n' +  input_chars + '\"' + '\\n'\n",
    "    print(input_line)\n",
    "    f.write(input_line)\n",
    "\n",
    "    # print out predicted characters\n",
    "    predict_line = 'predicted chars = ' + '\\n' +  predict_input + '\"' + '\\n'\n",
    "    print(predict_line)\n",
    "    f.write(predict_line)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
